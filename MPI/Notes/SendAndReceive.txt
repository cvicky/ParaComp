
http://mpitutorial.com/tutorials/mpi-send-and-receive/

///////////////////////////////////////
Blocking Point-to-Point Communication
///////////////////////////////////////

===========================================
MPI Send and Receive

-almost every single function in MPI can be implemented with basic send and receive calls

Overview:
-blocking and receiving functions
-other basic concepts associated with transmitting data using MPI

Sending and Receiving
-first, process A decides a message needs to be sent to process B
-process A then packs all of its necessary data into a buffer for process B
	-buffers are often referred to as envelopes (messages are packed into them)
-after data is packed into buffer, the communication device (network) is responsible for routing the message to proper location
	-location of message is defined by process’s rank

-even though message is routed to B, process B still needs to acknowledge that it wants to receive A’s data in the first place (YEA, CONSENT)
-once B acknowledges that it wants to receive A’s data, the data has been transmitted 
	-data may even go back and forth

-sometimes A might have to send different types of messages to B
-instead of B having to differentiate all these messages, MPI allows sender and receivers to specify message IDs (aka tags)
-when process B requests a message with a certain tag number, messages with different tags will be buffered by the network until B is ready for them

Functions:

MPI_Send(
    void* data,
    int count,
    MPI_Datatype datatype,
    int destination,
    int tag,
    MPI_Comm communicator)

MPI_Recv(
    void* data,
    int count,
    MPI_Datatype datatype,
    int source,
    int tag,
    MPI_Comm communicator,
    MPI_Status* status)

-first arg is the data buffer
-2nd and 3rd are the count and type of elements that reside in the butter
-MPI_Send will send the exact count of elements
-MPI_Recv will receive AT MOST the count of elements
-4th and 5th args specify the rank of the sending/receiving process and the tag of the message
-6th arg specifies the communicator
-last arg (for MPI_Recv ONLY) provides info about the received message

Elementary MPI datatypes

MPI datatype		C equivalent
MPI_SHORT		short int
MPI_INT			int
MPI_LONG		long int
MPI_LONG_LONG		long long int
MPI_UNSIGNED_CHAR	unsigned char
MPI_UNSIGNED_SHORT	unsigned short int
MPI_UNSIGNED		unsigned int
MPI_UNSIGNED_LONG	unsigned long int
MPI_UNSIGNED_LONG_LONG	unsigned long long int
MPI_FLOAT		float
MPI_DOUBLE		double
MPI_LONG_DOUBLE		long double
MPI_BYTE		char

MPI send/recv program
————————————————————————————————
// Find out rank, size
int world_rank;
MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
int world_size;
MPI_Comm_size(MPI_COMM_WORLD, &world_size);

int number;
if (world_rank == 0) {
    number = -1;
    MPI_Send(&number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
} else if (world_rank == 1) {
    MPI_Recv(&number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD,
             MPI_STATUS_IGNORE);
    printf("Process 1 received number %d from process 0\n",
           number);
}
//output: Process 1 received number -1 from process 0
—————————————————————————————

-MPI_Comm_rank is used to determine the rank of the process
-MPI_Comm_size is used to determine the world size 
-then the process zero initializes a number to the value of -1 and send this value to process one 

MPI Ping Pong Program
-processes use MPI_Send and MPI_Recv to continually bounce messages off of each other 

Program portion:
————————————
int ping_pong_count = 0;
int partner_rank = (world_rank + 1) % 2;
while (ping_pong_count < PING_PONG_LIMIT) {
    if (world_rank == ping_pong_count % 2) {
        // Increment the ping pong count before you send it
        ping_pong_count++;
        MPI_Send(&ping_pong_count, 1, MPI_INT, partner_rank, 0,
                 MPI_COMM_WORLD);
        printf("%d sent and incremented ping_pong_count "
               "%d to %d\n", world_rank, ping_pong_count,
               partner_rank);
    } else {
        MPI_Recv(&ping_pong_count, 1, MPI_INT, partner_rank, 0,
                 MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("%d received ping_pong_count %d from %d\n",
               world_rank, ping_pong_count, partner_rank);
    }
}
—————————————
//output:
0 sent and incremented ping_pong_count 1 to 1
0 received ping_pong_count 2 from 1
0 sent and incremented ping_pong_count 3 to 1
0 received ping_pong_count 4 from 1
0 sent and incremented ping_pong_count 5 to 1
0 received ping_pong_count 6 from 1
0 sent and incremented ping_pong_count 7 to 1
0 received ping_pong_count 8 from 1
0 sent and incremented ping_pong_count 9 to 1
0 received ping_pong_count 10 from 1
1 sent and incremented ping_pong_count 1 to 0
1 received ping_pong_count 2 from 0
1 sent and incremented ping_pong_count 3 to 0
1 received ping_pong_count 4 from 0
1 sent and incremented ping_pong_count 5 to 0
1 received ping_pong_count 6 from 0
1 sent and incremented ping_pong_count 7 to 0
1 received ping_pong_count 8 from 0
1 sent and incremented ping_pong_count 9 to 0
1 received ping_pong_count 10 from 0

——————————————

-ping_pong_count is initialized to 0, incremented at each ping pong step by the sending process
-as ping_pong_count is incremented, the processes take turns being sender and receiver
-after ping_pong_limit is reached, the processed will stop sending and receiving
-output may look different on other machines b/c of process scheduling

MPI Ring Problem
-this uses more than 2 processes
-value is passes around by all processes in a ring-like fashion

——————————
#include <mpi.h>
#include <stdio.h>
#include <stdlib.h>

int main(int argc, char** argv) {
  // Initialize the MPI environment
  MPI_Init(NULL, NULL);
  // Find out rank, size
  int world_rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
  int world_size;
  MPI_Comm_size(MPI_COMM_WORLD, &world_size);

  int token;
  // Receive from the lower process and send to the higher process. Take care
  // of the special case when you are the first process to prevent deadlock.
  if (world_rank != 0) {
    MPI_Recv(&token, 1, MPI_INT, world_rank - 1, 0, MPI_COMM_WORLD,
             MPI_STATUS_IGNORE);
    printf("Process %d received token %d from process %d\n", world_rank, token,
           world_rank - 1);
  } else {
    // Set the token's value if you are process 0
    token = -1;
  }
  MPI_Send(&token, 1, MPI_INT, (world_rank + 1) % world_size, 0,
           MPI_COMM_WORLD);
  // Now process 0 can receive from the last process. This makes sure that at
  // least one MPI_Send is initialized before all MPI_Recvs (again, to prevent
  // deadlock)
  if (world_rank == 0) {
    MPI_Recv(&token, 1, MPI_INT, world_size - 1, 0, MPI_COMM_WORLD,
             MPI_STATUS_IGNORE);
    printf("Process %d received token %d from process %d\n", world_rank, token,
           world_size - 1);
  }
  MPI_Finalize();
}
——————————
//output: with 5 processes
Process 1 received token -1 from process 0
Process 2 received token -1 from process 1
Process 3 received token -1 from process 2
Process 4 received token -1 from process 3
Process 0 received token -1 from process 4
—————————
-process 0 first sends -1 to process 1
-then -1 gets passed around the ring until it gets back to process 0 

-ring program initializes a value from process 0, and the value of passed around every single process
-program terminates when process 0 receives the value from the last process
-extra care is taken so that there is no deadlock
	-process 0 makes sure that it has completed its first send before it tries to receive the value from the last process
-all other processes call MPI_Recv (receiving from their neighboring lower processes) and then MPI_Send (sending the value to their neighboring higher processes) to pass the value along the ring

============================================

http://mpitutorial.com/tutorials/dynamic-receiving-with-mpi-probe-and-mpi-status/

Dynamic Receiving with MPI_probe and MPI_Status

-earlier programs were sending messages in which the length of the message was known beforehand

****-MPI natively supports dynamic messages with just a few addition function calls

MPI Status Structure
-the MPI_Recv operation takes the address of an MPI_Status structure as an arguments 
	-this can be ignores with MPI_STATUS_IGNORE
-if we pass an MPI_Status structure to the MPI_Recv function, MPI_Recv will be populated with additional info about the receive operation after it completes.

3 primary pieces of info:
1. rank of the sender :rank of the sender is stored in the MPI_Source elements of the structure
2. tag of the message: can be accessed by the MPI_TAG element of the structure (similar to MPI_SOURCE)
3. length of the message: it does not have a predefined element in the status structure
	-instead we have to dine out the length of the message with MPI_Get_count

function:
MPI_Get_count(
    MPI_Status* status,
    MPI_Datatype datatype,
    int* count)

-In MPI_Get_count, the user passes:
	-the MPI_Status structure
	-the datatype of the message
	-and count is returned

-Why is this necessary?
	-b/c MPI_Recv can take MPI_ANY_SOURCE for the rank of the sender and MPI_ANY_TAG for the tag of the message
-for this case, the MPI_Status structure is the only way to find out the actual sender and tag of the message
-MPI_Recv is not guaranteed to receive the entire amount of the elements passed a the argument to the function call
	-instead it receives the amount of elements that were sent to it (and returns an error if more elements were send than the desired receive amount)
-MPI_Get_count is used to determine the actual receive amount

An Example of Querying the MPi_Status Structure
-you can use MPI_Status by sending a random amount of number to a receiver, and the receiver then find out how many numbers were sent
	
———————————————
const int MAX_NUMBERS = 100;
int numbers[MAX_NUMBERS];
int number_amount;
if (world_rank == 0) {
    // Pick a random amount of integers to send to process one
    srand(time(NULL));
    number_amount = (rand() / (float)RAND_MAX) * MAX_NUMBERS;

    // Send the amount of integers to process one
    MPI_Send(numbers, number_amount, MPI_INT, 1, 0, MPI_COMM_WORLD);
    printf("0 sent %d numbers to 1\n", number_amount);
} else if (world_rank == 1) {
    MPI_Status status;
    // Receive at most MAX_NUMBERS from process zero
    MPI_Recv(numbers, MAX_NUMBERS, MPI_INT, 0, 0, MPI_COMM_WORLD,
             &status);

    // After receiving the message, check the status to determine
    // how many numbers were actually received
    MPI_Get_count(&status, MPI_INT, &number_amount);

    // Print off the amount of numbers, and also print additional
    // information in the status object
    printf("1 received %d numbers from 0. Message source = %d, "
           "tag = %d\n",
           number_amount, status.MPI_SOURCE, status.MPI_TAG);
}

—————————————
//output:
0 sent 92 numbers to 1
1 received 92 numbers from 0. Message source = 0, tag = 0
—————————
-process 0 sends a random amount of integers to process 1, which prints off into about the received message

-process 0 randomly sends up to MAX_NUMBERS integers to process 1
-process 1 then calls MPI_Recv for a total of MAX_NUMBERS integers
-although process 1 is passing MAX_NUMBERS as the arg to MPi_Recv, process 1 will receive AT MOST this amount of numbers
-process 1 calls MPI_Get_count with MPI_INT as the datatype to find out how many integers were actually received
	-along with printing off the size of the received message, process 1 prints off the source and tag of the message by accessing the MPI_SOURCE and MPI_TAG elements of the status structure

-the return value from MPI_Get_count is relative to the datatype which is passed

Using MPI_Probe to Find out the Message Size
-can use MPI_Status to our advantage more
-can use MPI_Probe to query the message size before actually receiving  the buffer with all the 

MPI_Probe(
    int source,
    int tag,
    MPI_Comm comm,
    MPI_Status* status)

-MPI_Probe looks similar to MPI_Recv, but MPI_Probe is basically an MPI_Recv that does everything but receive the message
-like MPI_Recv, MPI_Probe will block for a message with a matching tag and sender
-when the message is available, it will fill the status structure with information
-user can then use MPI_Recv to receive the actual message
——————————————
int number_amount;
if (world_rank == 0) {
    const int MAX_NUMBERS = 100;
    int numbers[MAX_NUMBERS];
    // Pick a random amount of integers to send to process one
    srand(time(NULL));
    number_amount = (rand() / (float)RAND_MAX) * MAX_NUMBERS;

    // Send the random amount of integers to process one
    MPI_Send(numbers, number_amount, MPI_INT, 1, 0, MPI_COMM_WORLD);
    printf("0 sent %d numbers to 1\n", number_amount);
} else if (world_rank == 1) {
    MPI_Status status;
    // Probe for an incoming message from process zero
    MPI_Probe(0, 0, MPI_COMM_WORLD, &status);

    // When probe returns, the status object has the size and other
    // attributes of the incoming message. Get the message size
    MPI_Get_count(&status, MPI_INT, &number_amount);

    // Allocate a buffer to hold the incoming numbers
    int* number_buf = (int*)malloc(sizeof(int) * number_amount);

    // Now receive the message with the allocated buffer
    MPI_Recv(number_buf, number_amount, MPI_INT, 0, 0,
             MPI_COMM_WORLD, MPI_STATUS_IGNORE);
    printf("1 dynamically received %d numbers from 0.\n",
           number_amount);
    free(number_buf);
}

——————————————
//output:
mpirun -n 2 ./probe
0 sent 93 numbers to 1
1 dynamically received 93 numbers from 0
———————————

-process 0 picks a random amount of numbers to send to process 1
-what’s different is that process 1 now calls MPI_Probe to find out how many elements process 0 is trying to send (using MPI_Get_count
-process 1 then allocates a buffer of the proper size and receives the numbers

-MPI_Probe forms the basis of many dynamic MPI applications



